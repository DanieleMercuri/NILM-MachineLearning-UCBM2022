{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_24388\\1430184262.py:5: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "data = pd.read_csv('Data/25day_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si etichetta il dataset con 4 classi:\n",
    "\n",
    "    1) Tutti spenti [0]\n",
    "    2) Solo lavatrice accesa [1]\n",
    "    3) Solo lavastoviglie accesa [2]\n",
    "    4) Solo forno acceso [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(len(data)):\n",
    "    if data['wahing_machine'].iloc[i]==0 and data['dishwasher'].iloc[i]==0 and data['oven'].iloc[i]==0:\n",
    "        label.append(0)\n",
    "    elif data['wahing_machine'].iloc[i]>0:\n",
    "        label.append(1)\n",
    "    elif data['dishwasher'].iloc[i]>0:\n",
    "        label.append(2)\n",
    "    elif data['oven'].iloc[i]>0:\n",
    "        label.append(3)\n",
    "data['Class'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droppa le colonne che non servono piu \n",
    "data.drop(['wahing_machine', 'dishwasher', 'oven'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "di seguito le istruzioni fronite per effettuare il corretto folding:\n",
    "\n",
    "Test set fold 01: \n",
    "Tutte le misure del giorno 2022-01-01\n",
    "\n",
    "\n",
    "Test set fold 02: \n",
    "Tutte le misure del giorno 2022-01-02\n",
    "\n",
    "Test set fold 03: \n",
    "Tutte le misure del giorno 2022-01-03\n",
    "\n",
    "…..\n",
    "\n",
    "\n",
    "Test set fold 09: \n",
    "Tutte le misure del giorno 2022-01-10\n",
    "Tutte le misure del giorno 2022-01-11\n",
    "\n",
    "Test set fold 10: \n",
    "Tutte le misure del giorno 2022-01-12\n",
    "Tutte le misure del giorno 2022-01-13 (dati disponibili fino alle 03:16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_list=[]\n",
    "Test_set1 =data[data['DateTime'].str.startswith('2022-01-01')]\n",
    "Test_set2 =data[data['DateTime'].str.startswith('2022-01-02')]\n",
    "Test_set3 =data[data['DateTime'].str.startswith('2022-01-03')]\n",
    "Test_set4 =data[data['DateTime'].str.startswith('2022-01-04')]\n",
    "Test_set5 =data[data['DateTime'].str.startswith('2022-01-05')]\n",
    "Test_set6 =data[data['DateTime'].str.startswith('2022-01-06')]\n",
    "Test_set7 =data[data['DateTime'].str.startswith('2022-01-07')]\n",
    "Test_set8 =data[(data['DateTime'].str.startswith('2022-01-08')) | (data['DateTime'].str.startswith('2022-01-09'))]\n",
    "Test_set9 =data[(data['DateTime'].str.startswith('2022-01-10')) | (data['DateTime'].str.startswith('2022-01-11'))]\n",
    "Test_set10 =data[(data['DateTime'].str.startswith('2022-01-12')) | (data['DateTime'].str.startswith('2022-01-13'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_24388\\1407526483.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Test_set=Test_set1.append([Test_set2,Test_set3,Test_set4,Test_set5,Test_set6,Test_set7,Test_set8,Test_set9,Test_set10])\n"
     ]
    }
   ],
   "source": [
    "test_set_list= [Test_set1, Test_set2, Test_set3, Test_set4, Test_set5, Test_set6, Test_set7, Test_set8, Test_set9, Test_set10]\n",
    "Test_set=Test_set1.append([Test_set2,Test_set3,Test_set4,Test_set5,Test_set6,Test_set7,Test_set8,Test_set9,Test_set10])\n",
    "Training_set= data.drop(Test_set.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "725760"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(Training_set.drop(['DateTime', 'Class'], axis=1), Training_set.Class, test_size=0.3, random_state= 8) \n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'min_samples_leaf': 50, 'n_estimators': 100}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'min_samples_leaf': [50, 100, 150],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_val, y_val)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1053198    3817     579     373]\n",
      " [   2874   32858       0       0]\n",
      " [   5148     594    8909       0]\n",
      " [   6154     804       1    7891]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99   1057967\n",
      "           1       0.86      0.92      0.89     35732\n",
      "           2       0.94      0.61      0.74     14651\n",
      "           3       0.95      0.53      0.68     14850\n",
      "\n",
      "    accuracy                           0.98   1123200\n",
      "   macro avg       0.94      0.76      0.83   1123200\n",
      "weighted avg       0.98      0.98      0.98   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1° addestramento\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_leaf=50)\n",
    "clf.fit(X_train, y_train)\n",
    "y_preds= clf.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1007868   25973   10260   13866]\n",
      " [   8745   25517     595     875]\n",
      " [   3671     529    8151    2300]\n",
      " [   4051    4255     456    6088]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97   1057967\n",
      "           1       0.45      0.71      0.55     35732\n",
      "           2       0.42      0.56      0.48     14651\n",
      "           3       0.26      0.41      0.32     14850\n",
      "\n",
      "    accuracy                           0.93   1123200\n",
      "   macro avg       0.53      0.66      0.58   1123200\n",
      "weighted avg       0.95      0.93      0.94   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2° addestramento\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "model =GaussianNB()\n",
    "ovr_g = OneVsRestClassifier(model)\n",
    "ovr_g.fit(X_train, y_train)\n",
    "predicted = ovr_g.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1004991   14300   11758   26918]\n",
      " [   7816   22951     423    4542]\n",
      " [   3557     546    9357    1191]\n",
      " [   4051    1074     201    9524]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97   1057967\n",
      "           1       0.59      0.64      0.62     35732\n",
      "           2       0.43      0.64      0.51     14651\n",
      "           3       0.23      0.64      0.33     14850\n",
      "\n",
      "    accuracy                           0.93   1123200\n",
      "   macro avg       0.56      0.72      0.61   1123200\n",
      "weighted avg       0.96      0.93      0.94   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2° addestramento\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "model =GaussianNB()\n",
    "ovo_g = OneVsOneClassifier(model)\n",
    "ovo_g.fit(X_train, y_train)\n",
    "predicted = ovo_g.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1049559     152       0    8256]\n",
      " [  27828    6226       0    1678]\n",
      " [   5126    9415       0     110]\n",
      " [   8294       1       0    6555]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98   1057967\n",
      "           1       0.39      0.17      0.24     35732\n",
      "           2       0.00      0.00      0.00     14651\n",
      "           3       0.39      0.44      0.42     14850\n",
      "\n",
      "    accuracy                           0.95   1123200\n",
      "   macro avg       0.44      0.40      0.41   1123200\n",
      "weighted avg       0.92      0.95      0.93   1123200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#3° addestramento\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "model = SVC(max_iter=1000)\n",
    "ovr = OneVsRestClassifier(model)\n",
    "ovr.fit(X_train, y_train)\n",
    "predicted = ovr.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensamble classificatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1055862    1401      33     671]\n",
      " [   9001   26728       0       3]\n",
      " [   5176     547    8928       0]\n",
      " [   4949       4      37    9860]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99   1057967\n",
      "           1       0.93      0.75      0.83     35732\n",
      "           2       0.99      0.61      0.76     14651\n",
      "           3       0.94      0.66      0.78     14850\n",
      "\n",
      "    accuracy                           0.98   1123200\n",
      "   macro avg       0.96      0.75      0.84   1123200\n",
      "weighted avg       0.98      0.98      0.98   1123200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor clf, label in zip([ovr, clf, ovo_g, eclf], [\\'one_VS_Rest\\', \\'Random Forest\\', \\'naive Bayes\\', \\'Ensemble\\']):\\n    scores = cross_val_score(clf, X_t, y_t, scoring=\\'accuracy\\', cv=5)\\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_t, y_train, y_t = train_test_split(Test_set.drop(['DateTime', 'Class'], axis=1), Test_set.Class, test_size=0.01, random_state= 8) \n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('ovr', ovr), ('rf', clf), ('gnb', ovo_g)],voting='hard')\n",
    "\n",
    "eclf.fit(X_t,y_t)\n",
    "predicted = eclf.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))\n",
    "\n",
    "'''\n",
    "for clf, label in zip([ovr, clf, ovo_g, eclf], ['one_VS_Rest', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_t, y_t, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "47e3f425e1f5e080840b02324288bfe2474c53b4d8fc90d3d863797934e6a5da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
