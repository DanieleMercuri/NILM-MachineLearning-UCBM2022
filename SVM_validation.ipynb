{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_9856\\1430184262.py:5: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "data = pd.read_csv('Data/25day_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si etichetta il dataset con 4 classi:\n",
    "\n",
    "    1) Tutti spenti [0]\n",
    "    2) Solo lavatrice accesa [1]\n",
    "    3) Solo lavastoviglie accesa [2]\n",
    "    4) Solo forno acceso [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(len(data)):\n",
    "    if data['wahing_machine'].iloc[i]==0 and data['dishwasher'].iloc[i]==0 and data['oven'].iloc[i]==0:\n",
    "        label.append(0)\n",
    "    elif data['wahing_machine'].iloc[i]>0:\n",
    "        label.append(1)\n",
    "    elif data['dishwasher'].iloc[i]>0:\n",
    "        label.append(2)\n",
    "    elif data['oven'].iloc[i]>0:\n",
    "        label.append(3)\n",
    "data['Class'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droppa le colonne che non servono piu \n",
    "data.drop(['wahing_machine', 'dishwasher', 'oven'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "di seguito le istruzioni fronite per effettuare il corretto folding:\n",
    "\n",
    "Test set fold 01: \n",
    "Tutte le misure del giorno 2022-01-01\n",
    "\n",
    "\n",
    "Test set fold 02: \n",
    "Tutte le misure del giorno 2022-01-02\n",
    "\n",
    "Test set fold 03: \n",
    "Tutte le misure del giorno 2022-01-03\n",
    "\n",
    "…..\n",
    "\n",
    "\n",
    "Test set fold 09: \n",
    "Tutte le misure del giorno 2022-01-10\n",
    "Tutte le misure del giorno 2022-01-11\n",
    "\n",
    "Test set fold 10: \n",
    "Tutte le misure del giorno 2022-01-12\n",
    "Tutte le misure del giorno 2022-01-13 (dati disponibili fino alle 03:16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_list=[]\n",
    "Test_set1 =data[data['DateTime'].str.startswith('2022-01-01')]\n",
    "Test_set2 =data[data['DateTime'].str.startswith('2022-01-02')]\n",
    "Test_set3 =data[data['DateTime'].str.startswith('2022-01-03')]\n",
    "Test_set4 =data[data['DateTime'].str.startswith('2022-01-04')]\n",
    "Test_set5 =data[data['DateTime'].str.startswith('2022-01-05')]\n",
    "Test_set6 =data[data['DateTime'].str.startswith('2022-01-06')]\n",
    "Test_set7 =data[data['DateTime'].str.startswith('2022-01-07')]\n",
    "Test_set8 =data[(data['DateTime'].str.startswith('2022-01-08')) | (data['DateTime'].str.startswith('2022-01-09'))]\n",
    "Test_set9 =data[(data['DateTime'].str.startswith('2022-01-10')) | (data['DateTime'].str.startswith('2022-01-11'))]\n",
    "Test_set10 =data[(data['DateTime'].str.startswith('2022-01-12')) | (data['DateTime'].str.startswith('2022-01-13'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_9856\\1407526483.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Test_set=Test_set1.append([Test_set2,Test_set3,Test_set4,Test_set5,Test_set6,Test_set7,Test_set8,Test_set9,Test_set10])\n"
     ]
    }
   ],
   "source": [
    "test_set_list= [Test_set1, Test_set2, Test_set3, Test_set4, Test_set5, Test_set6, Test_set7, Test_set8, Test_set9, Test_set10]\n",
    "Test_set=Test_set1.append([Test_set2,Test_set3,Test_set4,Test_set5,Test_set6,Test_set7,Test_set8,Test_set9,Test_set10])\n",
    "Training_set= data.drop(Test_set.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026432 10368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(Training_set.drop(['DateTime', 'Class'], axis=1), Training_set.Class, test_size=0.01, random_state= 8) \n",
    "\n",
    "print(len(X_train),len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'decision_function_shape': 'ovo', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VALIDATION SVM OVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':[1, 10], 'decision_function_shape' : ['ovo','ovr']}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_val, y_val)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 967046, 1: 41769, 2: 13538, 3: 4079}) 1026432\n",
      "Counter({0: 339709, 1: 41769, 2: 13538, 3: 4079}) 399095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(Training_set.drop(['DateTime', 'Class'], axis=1), Training_set.Class, test_size= 0.01, random_state= 8) \n",
    "\n",
    "#imputation\n",
    "from imblearn.under_sampling  import RandomUnderSampler\n",
    "from collections import Counter\n",
    "print(Counter(y_train), y_train.count())\n",
    "n= 400000 - (y_train.values == 1).sum() - (y_train.values == 3).sum() - (y_train.values == 2).sum()\n",
    "undersample = RandomUnderSampler(sampling_strategy={0: n-905, 1: (y_train.values == 1).sum(), 2: (y_train.values == 2).sum(), 3: (y_train.values == 3).sum()})\n",
    "X_new, y_new = undersample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_new), y_new.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026432"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(X_train, y_train, test_size = 0.01, random_state= 8)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 967046, 1: 41769, 2: 13538, 3: 4079}) 1026432\n",
      "Counter({0: 4079, 1: 4079, 2: 4079, 3: 4079}) 16316\n"
     ]
    }
   ],
   "source": [
    "#print(Counter(y_val1),y_val.count())\n",
    "print(Counter(y_train),y_train.count())\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy='auto')\n",
    "X_new, y_new = undersample.fit_resample(X_train, y_train)\n",
    "print(Counter(y_new), y_new.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 40}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VALIDATION SVM OVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "parameters = {'C':[1, 10, 40, 30, 20]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_val, y_val)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stats.stackexchange.com/questions/437072/use-f1-score-in-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[836009 152566  62153   7239]\n",
      " [ 15474  19640    333    285]\n",
      " [  1985   3274   9281    111]\n",
      " [  2245   2572    291   9742]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87   1057967\n",
      "           1       0.11      0.55      0.18     35732\n",
      "           2       0.13      0.63      0.21     14651\n",
      "           3       0.56      0.66      0.60     14850\n",
      "\n",
      "    accuracy                           0.78   1123200\n",
      "   macro avg       0.44      0.66      0.47   1123200\n",
      "weighted avg       0.93      0.78      0.84   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C=40, kernel='rbf', decision_function_shape='ovo')\n",
    "model.fit(X_new, y_new)\n",
    "y_preds=model.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[836009 152566  62153   7239]\n",
      " [ 15474  19640    333    285]\n",
      " [  1985   3274   9281    111]\n",
      " [  2245   2572    291   9742]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87   1057967\n",
      "           1       0.11      0.55      0.18     35732\n",
      "           2       0.13      0.63      0.21     14651\n",
      "           3       0.56      0.66      0.60     14850\n",
      "\n",
      "    accuracy                           0.78   1123200\n",
      "   macro avg       0.44      0.66      0.47   1123200\n",
      "weighted avg       0.93      0.78      0.84   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=40, kernel='rbf', decision_function_shape='ovr')\n",
    "model.fit(X_new, y_new)\n",
    "y_preds=model.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[26439 49549  5102     5]\n",
      " [    0  1022     2     0]\n",
      " [   42  1107  2365    63]\n",
      " [    0     1     0   703]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.49     81095\n",
      "           1       0.02      1.00      0.04      1024\n",
      "           2       0.32      0.66      0.43      3577\n",
      "           3       0.91      1.00      0.95       704\n",
      "\n",
      "    accuracy                           0.35     86400\n",
      "   macro avg       0.56      0.75      0.48     86400\n",
      "weighted avg       0.96      0.35      0.49     86400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Test_set=test_set_list[2]\n",
    "y_preds=model.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[787464 148341  82257  39905]\n",
      " [ 16410  14162   2678   2482]\n",
      " [  3141   2179   9186    145]\n",
      " [  1639   2375    840   9996]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.74      0.84   1057967\n",
      "           1       0.08      0.40      0.14     35732\n",
      "           2       0.10      0.63      0.17     14651\n",
      "           3       0.19      0.67      0.30     14850\n",
      "\n",
      "    accuracy                           0.73   1123200\n",
      "   macro avg       0.34      0.61      0.36   1123200\n",
      "weighted avg       0.92      0.73      0.81   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=15, kernel='rbf', decision_function_shape='ovr')\n",
    "model.fit(X_new, y_new)\n",
    "y_preds=model.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1017369   12720    4684   23194]\n",
      " [  24740    1065    4661    5266]\n",
      " [   4940     731    8084     896]\n",
      " [   3095     964     796    9995]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97   1057967\n",
      "           1       0.07      0.03      0.04     35732\n",
      "           2       0.44      0.55      0.49     14651\n",
      "           3       0.25      0.67      0.37     14850\n",
      "\n",
      "    accuracy                           0.92   1123200\n",
      "   macro avg       0.43      0.55      0.47   1123200\n",
      "weighted avg       0.92      0.92      0.92   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=15, kernel='poly', decision_function_shape='ovr')\n",
    "model.fit(X_new, y_new)\n",
    "y_preds=model.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATION SVM OVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "parameters = {'C':[1, 10, 20, 30, 20]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_val, y_val)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[978802  64053   5197   9915]\n",
      " [ 21350  14265     50     67]\n",
      " [  4385   3249   6984     33]\n",
      " [  7322   4770      5   2753]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95   1057967\n",
      "           1       0.17      0.40      0.23     35732\n",
      "           2       0.57      0.48      0.52     14651\n",
      "           3       0.22      0.19      0.20     14850\n",
      "\n",
      "    accuracy                           0.89   1123200\n",
      "   macro avg       0.48      0.50      0.47   1123200\n",
      "weighted avg       0.93      0.89      0.91   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_preds=neigh.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[921571 115623   8516  12257]\n",
      " [ 18524  17037     81     90]\n",
      " [  3860   3688   7057     46]\n",
      " [  6515   5279     39   3017]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92   1057967\n",
      "           1       0.12      0.48      0.19     35732\n",
      "           2       0.45      0.48      0.47     14651\n",
      "           3       0.20      0.20      0.20     14850\n",
      "\n",
      "    accuracy                           0.84   1123200\n",
      "   macro avg       0.43      0.51      0.44   1123200\n",
      "weighted avg       0.93      0.84      0.88   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#knn con imputation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh.fit(X_new, y_new)\n",
    "y_preds=neigh.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VALIDATION SVM OVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(decision_function_shape = 'ovo')\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_val, y_val)\n",
    "clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=10, kernel='rbf', decision_function_shape='ovo')\n",
    "model.fit(X_train, y_train)\n",
    "y_preds=neigh.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'min_samples_leaf': 50, 'n_estimators': 100}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'min_samples_leaf': [50, 100, 150],\n",
    "    'criterion' : ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_val, y_val)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1053198    3817     579     373]\n",
      " [   2874   32858       0       0]\n",
      " [   5148     594    8909       0]\n",
      " [   6154     804       1    7891]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99   1057967\n",
      "           1       0.86      0.92      0.89     35732\n",
      "           2       0.94      0.61      0.74     14651\n",
      "           3       0.95      0.53      0.68     14850\n",
      "\n",
      "    accuracy                           0.98   1123200\n",
      "   macro avg       0.94      0.76      0.83   1123200\n",
      "weighted avg       0.98      0.98      0.98   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1° addestramento\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Test_set= test_set_list[2]\n",
    "clf = RandomForestClassifier(n_estimators=100, criterion='entropy', min_samples_leaf=50)\n",
    "clf.fit(X_train, y_train)\n",
    "y_preds= clf.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,y_preds)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1007868   25973   10260   13866]\n",
      " [   8745   25517     595     875]\n",
      " [   3671     529    8151    2300]\n",
      " [   4051    4255     456    6088]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97   1057967\n",
      "           1       0.45      0.71      0.55     35732\n",
      "           2       0.42      0.56      0.48     14651\n",
      "           3       0.26      0.41      0.32     14850\n",
      "\n",
      "    accuracy                           0.93   1123200\n",
      "   macro avg       0.53      0.66      0.58   1123200\n",
      "weighted avg       0.95      0.93      0.94   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2° addestramento\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "model =GaussianNB()\n",
    "ovr_g = OneVsRestClassifier(model)\n",
    "ovr_g.fit(X_train, y_train)\n",
    "predicted = ovo_r.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1004991   14300   11758   26918]\n",
      " [   7816   22951     423    4542]\n",
      " [   3557     546    9357    1191]\n",
      " [   4051    1074     201    9524]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97   1057967\n",
      "           1       0.59      0.64      0.62     35732\n",
      "           2       0.43      0.64      0.51     14651\n",
      "           3       0.23      0.64      0.33     14850\n",
      "\n",
      "    accuracy                           0.93   1123200\n",
      "   macro avg       0.56      0.72      0.61   1123200\n",
      "weighted avg       0.96      0.93      0.94   1123200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2° addestramento\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "model =GaussianNB()\n",
    "ovo_g = OneVsOneClassifier(model)\n",
    "ovo_g.fit(X_train, y_train)\n",
    "predicted = ovo_g.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1049559     152       0    8256]\n",
      " [  27828    6226       0    1678]\n",
      " [   5126    9415       0     110]\n",
      " [   8294       1       0    6555]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98   1057967\n",
      "           1       0.39      0.17      0.24     35732\n",
      "           2       0.00      0.00      0.00     14651\n",
      "           3       0.39      0.44      0.42     14850\n",
      "\n",
      "    accuracy                           0.95   1123200\n",
      "   macro avg       0.44      0.40      0.41   1123200\n",
      "weighted avg       0.92      0.95      0.93   1123200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#3° addestramento\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "model = SVC(max_iter=1000)\n",
    "ovr = OneVsRestClassifier(model)\n",
    "ovr.fit(X_train, y_train)\n",
    "predicted = ovr.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensamble classificatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\danie\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[1055862    1401      33     671]\n",
      " [   9001   26728       0       3]\n",
      " [   5176     547    8928       0]\n",
      " [   4949       4      37    9860]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99   1057967\n",
      "           1       0.93      0.75      0.83     35732\n",
      "           2       0.99      0.61      0.76     14651\n",
      "           3       0.94      0.66      0.78     14850\n",
      "\n",
      "    accuracy                           0.98   1123200\n",
      "   macro avg       0.96      0.75      0.84   1123200\n",
      "weighted avg       0.98      0.98      0.98   1123200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor clf, label in zip([ovr, clf, ovo_g, eclf], [\\'one_VS_Rest\\', \\'Random Forest\\', \\'naive Bayes\\', \\'Ensemble\\']):\\n    scores = cross_val_score(clf, X_t, y_t, scoring=\\'accuracy\\', cv=5)\\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_t, y_train, y_t = train_test_split(Test_set.drop(['DateTime', 'Class'], axis=1), Test_set.Class, test_size=0.01, random_state= 8) \n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('ovr', ovr), ('rf', clf), ('gnb', ovo_g)],voting='hard')\n",
    "\n",
    "eclf.fit(X_t,y_t)\n",
    "predicted = eclf.predict(Test_set.drop(['DateTime', 'Class'], axis=1))\n",
    "\n",
    "print(\"CM:\\n\" + str(confusion_matrix(Test_set.Class,predicted)) + \"\\n\")\n",
    "print(classification_report(Test_set.Class,predicted))\n",
    "\n",
    "'''\n",
    "for clf, label in zip([ovr, clf, ovo_g, eclf], ['one_VS_Rest', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_t, y_t, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111968 11232\n"
     ]
    }
   ],
   "source": [
    "X_train, X_t, y_train, y_t = train_test_split(Test_set.drop(['DateTime', 'Class'], axis=1), Test_set.Class, test_size=0.01, random_state= 8) \n",
    "print(len(X_train), len(X_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per esportare il modello utilizziamo pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "47e3f425e1f5e080840b02324288bfe2474c53b4d8fc90d3d863797934e6a5da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
