{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c7d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, classification_report, f1_score, recall_score\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d187cb1",
   "metadata": {},
   "source": [
    "Import del dataset in un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85dbcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/25day_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c877a262",
   "metadata": {},
   "source": [
    "Si etichetta il dataset con 4 classi:\n",
    "\n",
    "    1) Tutti i dispositivi spenti [0]\n",
    "    2) Solo la lavatrice accesa [1]\n",
    "    3) Solo la lavastoviglie accesa [2]\n",
    "    4) Solo il forno acceso [3]\n",
    "    \n",
    "Le altre combinazioni di dispositivi accesi non si verificano mai e quindi vengono esclusi a priori. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777fafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(len(data)):\n",
    "    if data['wahing_machine'].iloc[i]==0 and data['dishwasher'].iloc[i]==0 and data['oven'].iloc[i]==0:\n",
    "        label.append(0)\n",
    "    elif data['wahing_machine'].iloc[i]>0:\n",
    "        label.append(1)\n",
    "    elif data['dishwasher'].iloc[i]>0:\n",
    "        label.append(2)\n",
    "    elif data['oven'].iloc[i]>0:\n",
    "        label.append(3)\n",
    "data['Class'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a35e7",
   "metadata": {},
   "source": [
    "Codice per la creazione delle fold. Di seguito le istruzioni fronite per effettuare il corretto folding:\n",
    "\n",
    "Test set fold 01: Tutte le misure del giorno 2022-01-01\n",
    "\n",
    "Test set fold 02: Tutte le misure del giorno 2022-01-02\n",
    "\n",
    "Test set fold 03: Tutte le misure del giorno 2022-01-03\n",
    "\n",
    "…..\n",
    "\n",
    "Test set fold 09: Tutte le misure del giorno 2022-01-10 Tutte le misure del giorno 2022-01-11\n",
    "\n",
    "Test set fold 10: Tutte le misure del giorno 2022-01-12 Tutte le misure del giorno 2022-01-13 (dati disponibili fino alle 03:16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc86d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set1 =data[data['DateTime'].str.startswith('2022-01-01')]\n",
    "Test_set2 =data[data['DateTime'].str.startswith('2022-01-02')]\n",
    "Test_set3 =data[data['DateTime'].str.startswith('2022-01-03')]\n",
    "Test_set4 =data[data['DateTime'].str.startswith('2022-01-04')]\n",
    "Test_set5 =data[data['DateTime'].str.startswith('2022-01-05')]\n",
    "Test_set6 =data[data['DateTime'].str.startswith('2022-01-06')]\n",
    "Test_set7 =data[data['DateTime'].str.startswith('2022-01-07')]\n",
    "Test_set8 =data[(data['DateTime'].str.startswith('2022-01-08'))]\n",
    "Test_set9 =data[(data['DateTime'].str.startswith('2022-01-10')) | (data['DateTime'].str.startswith('2022-01-11'))]\n",
    "Test_set10 =data[(data['DateTime'].str.startswith('2022-01-12')) | (data['DateTime'].str.startswith('2022-01-13'))]\n",
    "test_set_list= [Test_set1, Test_set2, Test_set3, Test_set4, Test_set5, Test_set6, Test_set7, Test_set8, Test_set9, Test_set10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14549318",
   "metadata": {},
   "source": [
    "Train e test del modello per ogni fold creata nel passo precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20753142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[80403   494   720    48]\n",
      " [   78  3975     0     0]\n",
      " [    0     0     0     0]\n",
      " [  143     0     0   539]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     81665\n",
      "           1       0.89      0.98      0.93      4053\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.92      0.79      0.85       682\n",
      "\n",
      "    accuracy                           0.98     86400\n",
      "   macro avg       0.70      0.69      0.69     86400\n",
      "weighted avg       0.99      0.98      0.99     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[76726   841   267   435]\n",
      " [  634  6371     0     3]\n",
      " [    0     0     0     0]\n",
      " [   53     0     0  1070]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     78269\n",
      "           1       0.88      0.91      0.90      7008\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.71      0.95      0.81      1123\n",
      "\n",
      "    accuracy                           0.97     86400\n",
      "   macro avg       0.65      0.71      0.67     86400\n",
      "weighted avg       0.98      0.97      0.98     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[78985   807   274  1029]\n",
      " [  105   873     0    46]\n",
      " [  419   128  3030     0]\n",
      " [    0     0     0   704]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     81095\n",
      "           1       0.48      0.85      0.62      1024\n",
      "           2       0.92      0.85      0.88      3577\n",
      "           3       0.40      1.00      0.57       704\n",
      "\n",
      "    accuracy                           0.97     86400\n",
      "   macro avg       0.70      0.92      0.76     86400\n",
      "weighted avg       0.98      0.97      0.97     86400\n",
      "\n",
      "CM:\n",
      "[[81536    62    32   125]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]\n",
      " [  509  1226     4  2906]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     81755\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.96      0.63      0.76      4645\n",
      "\n",
      "    accuracy                           0.98     86400\n",
      "   macro avg       0.49      0.41      0.44     86400\n",
      "weighted avg       0.99      0.98      0.98     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[82101   625     5     4]\n",
      " [  138  3516     0    11]\n",
      " [    0     0     0     0]\n",
      " [    0     0     0     0]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     82735\n",
      "           1       0.85      0.96      0.90      3665\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99     86400\n",
      "   macro avg       0.46      0.49      0.47     86400\n",
      "weighted avg       0.99      0.99      0.99     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[81439   825    79    79]\n",
      " [    0     0     0     0]\n",
      " [   46   463  3469     0]\n",
      " [    0     0     0     0]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     82422\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.98      0.87      0.92      3978\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     86400\n",
      "   macro avg       0.49      0.47      0.48     86400\n",
      "weighted avg       1.00      0.98      0.99     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[79407   494   325   730]\n",
      " [  232  3026     0     0]\n",
      " [    0     0     0     0]\n",
      " [  601     2     4  1579]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     80956\n",
      "           1       0.86      0.93      0.89      3258\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.68      0.72      0.70      2186\n",
      "\n",
      "    accuracy                           0.97     86400\n",
      "   macro avg       0.63      0.66      0.65     86400\n",
      "weighted avg       0.98      0.97      0.97     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[78952   383  1729   375]\n",
      " [  128  4027     0     0]\n",
      " [    0     0     0     0]\n",
      " [  273     3     0   530]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     81439\n",
      "           1       0.91      0.97      0.94      4155\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.59      0.66      0.62       806\n",
      "\n",
      "    accuracy                           0.97     86400\n",
      "   macro avg       0.62      0.65      0.64     86400\n",
      "weighted avg       0.99      0.97      0.98     86400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[166634    419    542    636]\n",
      " [   111   2673      0      6]\n",
      " [     0      0      0      0]\n",
      " [   663      0      0   1116]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    168231\n",
      "           1       0.86      0.96      0.91      2790\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.63      0.63      0.63      1779\n",
      "\n",
      "    accuracy                           0.99    172800\n",
      "   macro avg       0.62      0.64      0.63    172800\n",
      "weighted avg       0.99      0.99      0.99    172800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\massi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM:\n",
      "[[157684    815    712    711]\n",
      " [   374   6112      0      4]\n",
      " [   232      1   3230      0]\n",
      " [    81      1      1   2842]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    159922\n",
      "           1       0.88      0.94      0.91      6490\n",
      "           2       0.82      0.93      0.87      3463\n",
      "           3       0.80      0.97      0.88      2925\n",
      "\n",
      "    accuracy                           0.98    172800\n",
      "   macro avg       0.87      0.96      0.91    172800\n",
      "weighted avg       0.98      0.98      0.98    172800\n",
      "\n",
      "0    0.989574\n",
      "1    0.874846\n",
      "2    0.891608\n",
      "3    0.727138\n",
      "dtype: float64\n",
      "0    0.984339\n",
      "1    0.937444\n",
      "2    0.883947\n",
      "3    0.793448\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Dizionari per salvarsi le prestazioni richieste \n",
    "f_score={}\n",
    "recall={}\n",
    "\n",
    "#Ciclo per scorrere le fold di test e trainare un modello per ognuna di esse\n",
    "-for i in range(len(test_set_list)):\n",
    "    \n",
    "    #Creazione delle X_train e y_train togliendo tutti i record del test set, cioè la fold i-esima\n",
    "    dfi = data.drop(test_set_list[i].index)\n",
    "    y_= dfi.Class\n",
    "    X_= dfi.drop(['DateTime', 'Class', 'wahing_machine', 'dishwasher', 'oven'], axis=1)\n",
    "    \n",
    "    #Prendo intervalli di 5 valori consecutivi e li sostituisco con la media...\n",
    "    X = X_.groupby(np.arange(len(dfi))//5).mean()\n",
    "    #...per le classi scelgo quella piu rappresentata dei 5 campioni\n",
    "    y = y_.groupby(np.arange(len(dfi))//5).agg(lambda x:x.value_counts().index[0])\n",
    "\n",
    "    #Undersampling per equilibrare il dataset altrimenti molto sbilanciato\n",
    "    two= int((y.values == 2).sum()) \n",
    "    three= int((y.values == 3).sum())\n",
    "    undersample = RandomUnderSampler(sampling_strategy={0: 10000, 1: 10000, 2: two, 3: three})\n",
    "    X_new, y_new = undersample.fit_resample(X, y)\n",
    "    \n",
    "    #Inizializzazione del modello della Random Forest con i parametri scelti tramite la validation\n",
    "    clf = RandomForestClassifier(\n",
    "                                   class_weight= {0: 9, 1: 1, 2: 1, 3: 6},\n",
    "                                   criterion= 'entropy', \n",
    "                                   max_depth= 10,\n",
    "                                   max_features= 'sqrt',\n",
    "                                   max_samples= 0.3,\n",
    "                                   n_estimators= 300\n",
    "                                )\n",
    "    \n",
    "    #fit del modello e salvo su file  \n",
    "    clf.fit(X_new, y_new)\n",
    "    dump(clf, f'Models_RF/RandomForest_Fold{i}.sav')\n",
    "    \n",
    "    #Creazione di X_test e y_test prendendo i campioni della fold \n",
    "    X_test = test_set_list[i].copy().drop(['DateTime', 'Class', 'wahing_machine', 'dishwasher', 'oven'], axis=1)\n",
    "    y_test = test_set_list[i].Class\n",
    "    \n",
    "    #Predizione del modello sulle X_test\n",
    "    y_preds = clf.predict(X_test)\n",
    "    \n",
    "    #Stampa della matrice di confusione generata dalla predizione e relative performance ottenute\n",
    "    print(\"CM:\\n\" + str(confusion_matrix(y_test,y_preds)) + \"\\n\")\n",
    "    print(classification_report(y_test,y_preds))\n",
    "    \n",
    "    #Calcolo delle metriche di F1_Score e Recall per ogni classe\n",
    "    r = recall_score(y_test,y_preds, average= None) \n",
    "    f = f1_score(y_test,y_preds, average= None)\n",
    "    f_score[i] = f\n",
    "    recall[i] = r \n",
    " \n",
    "#Calcolo delle metriche medie ottenute da tutte le fold\n",
    "f1= pd.DataFrame.from_dict(f_score, orient='index').replace(0, np.nan)\n",
    "print(f1.mean(axis=0, skipna=True))\n",
    "r1= pd.DataFrame.from_dict(recall, orient='index').replace(0, np.nan)\n",
    "print(r1.mean(axis=0, skipna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7768d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716128670992677"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.iloc[:, 1:].mean(axis=0, skipna=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a748370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.849488\n",
      "1    0.813379\n",
      "2    0.567056\n",
      "3    0.757165\n",
      "4         NaN\n",
      "5         NaN\n",
      "6    0.702558\n",
      "7    0.619521\n",
      "8    0.631043\n",
      "9    0.876890\n",
      "Name: 3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f1.transpose().iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80a832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
